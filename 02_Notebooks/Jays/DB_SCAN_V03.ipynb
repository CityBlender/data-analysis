{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some stuff\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#need to translate from wgs to bng to do spatial clustering\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly info\n",
    "plotly.tools.set_credentials_file(username='aclong', api_key='A9dlryDYONXram1rzbki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies number of rows to show\n",
    "pd.set_option('display.max_rows', 300) \n",
    "\n",
    "# specifies default number format to 4 decimal places\n",
    "pd.options.display.float_format = '{:40,.4f}'.format \n",
    "\n",
    "# specifies that graphs should use ggplot styling\n",
    "plt.style.use('ggplot') \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .env variable\n",
    "# base_dir = 'D:\\Documentos\\GitHub\\CityBlender'\n",
    "# dotenv_file = os.path.join(base_dir, '.env')\n",
    "\n",
    "base_dir = 'C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Analysis Test/'\n",
    "dotenv_file = os.path.join(base_dir, '.env')\n",
    "\n",
    "\n",
    "if os.path.isfile(dotenv_file):\n",
    "    load_dotenv(dotenv_file, verbose=True)\n",
    "    \n",
    "db_uri = os.getenv('DB_URI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "none:27017: [Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2a195d7d245c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# If it's ok it should return a 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdb_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlondon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"serverStatus\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ok'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\database.py\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, **kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \"\"\"\n\u001b[0;32m    528\u001b[0m         \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__client\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket_for_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_preference\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslave_ok\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m             return self._command(sock_info, command, slave_ok, value,\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_preference\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_socket_for_reads\u001b[1;34m(self, read_preference)\u001b[0m\n\u001b[0;32m    980\u001b[0m         \u001b[0mtopology\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_topology\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m         \u001b[0msingle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopology_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTOPOLOGY_TYPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mserver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_preference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m             slave_ok = (single and not sock_info.is_mongos) or (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[1;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[0;32m    222\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[0;32m    223\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                                                  address))\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[1;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             server_descriptions = self._select_servers_loop(\n\u001b[1;32m--> 183\u001b[1;33m                 selector, server_timeout, address)\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             return [self.get_server_by_address(sd.address)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[1;34m(self, selector, timeout, address)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[1;32m--> 199\u001b[1;33m                     self._error_message(selector))\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: none:27017: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "# create a new MongoDB Client\n",
    "db_client = MongoClient(str(db_uri))\n",
    "\n",
    "# If it's ok it should return a 1.0\n",
    "db_client.london.command(\"serverStatus\")['ok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a database to connect to (.london)\n",
    "db_london = db_client.london\n",
    "\n",
    "# choose a collection\n",
    "db_london_events = db_london['events']\n",
    "db_london_artist = db_london['artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup all the documents in a collection\n",
    "db_london_events.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.DataFrame(list(db_london_events.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For instance in the first row there are 3 events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put this in the date fomrat\n",
    "events['date'] = [(datetime.strptime(events['date'][x], '%Y-%m-%d')) for x in range(len(events['date']))]\n",
    "\n",
    "# Convert the dates into day name\n",
    "events['date_name'] = [(events['date'][x].strftime(\"%A\")) for x in range(len(events['date']))]\n",
    "\n",
    "# Lat & Long\n",
    "events['lat'] = [(events['location'][x]['lat']) for x in range(len(events['location']))]\n",
    "events['lng'] = [(events['location'][x]['lng']) for x in range(len(events['location']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "plotly.tools.set_credentials_file(username='cohenjota', api_key='I6zLnEN42oNTpZv36icg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from mpl_toolkits.basemap import Basemap   \n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon\n",
    "from shapely.prepared import prep\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import Normalize\n",
    "from descartes import PolygonPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB SCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(events['lng'], events['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = events[events['lat']<52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(subset['lng'], subset['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset[subset['lat']>51.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(subset['lng'], subset['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCANING_DB(eps_var = 0.1 , min_sample_var = 5, db = subset, lat_var = 'lat', lng_var = 'lng'):\n",
    "    dbscan = DBSCAN(eps=eps_var, min_samples = min_sample_var)\n",
    "#     print(dbscan) \n",
    "    arrey_coords = db[[lat_var, lng_var]].values\n",
    "    #print(arrey_coords)\n",
    "    #try clustering out on the whole dataset\n",
    "    dbscan_result = dbscan.fit(arrey_coords)\n",
    "    dbscan_result_lbls = dbscan_result.labels_\n",
    "    return(dbscan_result_lbls)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 0.001)\n",
    "subset['cluster'] = fitted\n",
    "print(len(subset['cluster'].unique()))\n",
    "print(subset.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "subset['cluster'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 0.01)\n",
    "subset['cluster'] = fitted\n",
    "print(len(subset['cluster'].unique()))\n",
    "print(subset.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "subset['cluster'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 0.025)\n",
    "subset['cluster'] = fitted\n",
    "print(len(subset['cluster'].unique()))\n",
    "print(subset.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "subset['cluster'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 0.06)\n",
    "subset['cluster'] = fitted\n",
    "print(len(subset['cluster'].unique()))\n",
    "print(subset.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "subset['cluster'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to BNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to translate from wgs to bng to do spatial clustering\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do clustering locations need to be in BNG so that distances are in metres\n",
    "#Define projections using EPSG codes\n",
    "wgs84=pyproj.Proj(\"+init=EPSG:4326\") # LatLon with WGS84 datum used by songkick\n",
    "osgb36=pyproj.Proj(\"+init=EPSG:27700\") # UK Ordnance Survey, 1936 datum, for locations in eastings/northings/metres\n",
    "\n",
    "#create a new pd without NaNs\n",
    "londonEventsdfNoNan = subset[subset['lat'].notnull()]\n",
    "\n",
    "#make new columns for the new latlng\n",
    "londonEventsdfNoNan['BNGnorthing'] = \"\"\n",
    "londonEventsdfNoNan['BNGeasting'] = \"\"\n",
    "\n",
    "#reset the index - londonEventsdfNoNan now main dataframe\n",
    "londonEventsdfNoNan = londonEventsdfNoNan.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run through the dataset and transform those coordinates\n",
    "origLat = []\n",
    "origLng = []\n",
    "\n",
    "for i in range(0,len(londonEventsdfNoNan)):\n",
    "    # print(i)\n",
    "    try:\n",
    "        origLat.append(londonEventsdfNoNan['lat'][i])\n",
    "        origLng.append(londonEventsdfNoNan['lng'][i])\n",
    "        \n",
    "    except:\n",
    "        origLat.append(np.nan)\n",
    "        origLng.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,lon = pyproj.transform(wgs84,osgb36,origLng,origLat)\n",
    "    \n",
    "londonEventsdfNoNan['BNGeasting'] = lat\n",
    "londonEventsdfNoNan['BNGnorthing'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now convert from object to numeric\n",
    "londonEventsdfNoNan['BNGnorthing'] = pd.to_numeric(londonEventsdfNoNan['BNGnorthing'])\n",
    "londonEventsdfNoNan['BNGeasting'] = pd.to_numeric(londonEventsdfNoNan['BNGeasting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "londonEventsdfNoNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['lng'], londonEventsdfNoNan['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['BNGeasting'], londonEventsdfNoNan['BNGnorthing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['lat'], londonEventsdfNoNan['BNGnorthing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['lng'], londonEventsdfNoNan['BNGeasting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 750, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', db = londonEventsdfNoNan)\n",
    "londonEventsdfNoNan['cluster'] = fitted\n",
    "print(len(londonEventsdfNoNan['cluster'].unique()))\n",
    "print(londonEventsdfNoNan.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "londonEventsdfNoNan['cluster'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to subset the genre depending on which dataset\n",
    "def subset_by_genre(db, lib = 'spotify', words = 'reggae'):\n",
    "    return db[db[lib].astype(str).str.contains(words, case=False)]\n",
    "\n",
    "#create a genre compiling function\n",
    "def genre_df_compiler(genreName, db = londonEventsdfNoNan):\n",
    "    firstEventsdf = subset_by_genre(db, lib='spotify',words = genreName)\n",
    "    secondEventsdf = subset_by_genre(db, lib='lastfm',words = genreName)\n",
    "    allEventsdf = \"all\"+genreName+\"Events\" \n",
    "    allEventsdf = pd.concat([firstEventsdf, secondEventsdf])\n",
    "    allEventsdf = allEventsdf.drop_duplicates(subset='_id', keep='last')\n",
    "    return(allEventsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz =  genre_df_compiler('jazz', db = londonEventsdfNoNan)\n",
    "jazz.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 750, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', db = jazz)\n",
    "jazz['cluster'] = fitted\n",
    "print(len(jazz['cluster'].unique()))\n",
    "print(jazz.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "jazz['cluster'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for storing the clusternos per eps value\n",
    "clusterNoEps = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_df_genre(db = jazz, epsMin = 1, epsMax = 2000, epsStep = 10, colName = \"ClusterNosjazz\"):\n",
    "    clusterNos = []\n",
    "    epsValues = list(range(epsMin, epsMax, epsStep))\n",
    "    epsDF = pd.DataFrame(epsValues)\n",
    "    for i in epsValues:\n",
    "        fitted = SCANING_DB(eps_var = i, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', db = db)\n",
    "        db['cluster'] = fitted\n",
    "        clusterNos.append(len(db['cluster'].unique()))\n",
    "    epsDF[colName] = pd.DataFrame(clusterNos)\n",
    "    return epsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterNos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFjazz = eps_df_genre(db = jazz, colName = \"ClusterNosjazz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFevents = eps_df_genre(db = londonEventsdfNoNan, colName = \"ClusterNosevents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFjazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folk =  genre_df_compiler('folk', db = londonEventsdfNoNan)\n",
    "folk.reset_index(inplace = True)\n",
    "epsDFfolk = eps_df_genre(db = folk, colName = \"ClusterNosfolk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indie =  genre_df_compiler('indie', db = londonEventsdfNoNan)\n",
    "indie.reset_index(inplace = True)\n",
    "epsDFindie = eps_df_genre(db = indie, colName = \"ClusterNosindie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical =  genre_df_compiler('classical', db = londonEventsdfNoNan)\n",
    "classical.reset_index(inplace = True)\n",
    "epsDFclassical = eps_df_genre(db = classical, colName = \"ClusterNosclassical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house =  genre_df_compiler('house', db = londonEventsdfNoNan)\n",
    "house.reset_index(inplace = True)\n",
    "epsDFhouse = eps_df_genre(db = house, colName = \"ClusterNoshouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock =  genre_df_compiler('rock', db = londonEventsdfNoNan)\n",
    "rock.reset_index(inplace = True)\n",
    "epsDFrock = eps_df_genre(db = rock, colName = \"ClusterNosrock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reggae =  genre_df_compiler('rock', db = londonEventsdfNoNan)\n",
    "reggae.reset_index(inplace = True)\n",
    "epsDFreggae = eps_df_genre(db = reggae, colName = \"ClusterNosreggae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grime =  genre_df_compiler('grime', db = londonEventsdfNoNan)\n",
    "grime.reset_index(inplace = True)\n",
    "epsDFgrime = eps_df_genre(db = grime, colName = \"ClusterNosgrime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall = pd.concat([epsDFevents, epsDFjazz, epsDFfolk, epsDFclassical, epsDFgrime, epsDFreggae, epsDFrock, epsDFhouse, epsDFindie], axis=1, join_axes=[epsDFevents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall = epsDFall.loc[:,~epsDFall.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosevents'], \n",
    "                    name = 'All Events', \n",
    "                    line = dict(color = ('rgb(205, 12, 24)'), width = 4))\n",
    "trace1 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosjazz'], \n",
    "                    name = 'Jazz Events', \n",
    "                    line = dict(color = ('rgb(22, 96, 167)'), width = 4))\n",
    "trace2 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosfolk'], \n",
    "                    name = 'Folk Events', \n",
    "                    line = dict(color = ('rgb(100, 12, 24)'), width = 4))\n",
    "trace3 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosclassical'], \n",
    "                    name = 'Classical Events', \n",
    "                    line = dict(color = ('rgb(150, 96, 167)'), width = 4))\n",
    "trace4 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosgrime'], \n",
    "                    name = 'Grime Events', \n",
    "                    line = dict(color = ('rgb(70, 96, 167)'), width = 4))\n",
    "trace5 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosreggae'], \n",
    "                    name = 'Reggae Events', \n",
    "                    line = dict(color = ('rgb(175, 96, 167)'), width = 4))\n",
    "trace6 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosrock'], \n",
    "                    name = 'Rock Events', \n",
    "                    line = dict(color = ('rgb(255, 96, 167)'), width = 4))\n",
    "trace7 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNoshouse'], \n",
    "                    name = 'House Events', \n",
    "                    line = dict(color = ('rgb(0, 96, 167)'), width = 4))\n",
    "trace8 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosindie'], \n",
    "                    name = 'Indie Events', \n",
    "                    line = dict(color = ('rgb(70, 96, 100)'), width = 4))\n",
    "\n",
    "graphData = [\n",
    "#             trace0, \n",
    "             trace1, \n",
    "             trace2, \n",
    "             trace3, \n",
    "             trace4,\n",
    "             trace5,\n",
    "             trace6,\n",
    "             trace7,\n",
    "             trace8]\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title = 'No. Clusters at EPS values',\n",
    "              xaxis = dict(title = 'EPS Value'),\n",
    "              yaxis = dict(title = 'No. Clusters'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=graphData, layout=layout)\n",
    "py.iplot(fig, filename='styled-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get folium map of clusters\n",
    "#need to create the function to add labels of clusters to the dataframe\n",
    "#eps 500 minsamples 5\n",
    "# def SCANING_DB(eps_var = 0.1 , min_sample_var = 5, db = subset, lat_var = 'lat', lng_var = 'lng'):\n",
    "#     dbscan = DBSCAN(eps=eps_var, min_samples = min_sample_var)\n",
    "#     print(dbscan) \n",
    "#     arrey_coords = db[[lat_var, lng_var]].values\n",
    "    #print(arrey_coords)\n",
    "# try clustering out on the whole dataset\n",
    "#     dbscan_result = dbscan.fit(arrey_coords)\n",
    "#     dbscan_result_lbls = dbscan_result.labels_\n",
    "#     return(dbscan_result_lbls)\n",
    "\n",
    "dbscanJazzLabels = SCANING_DB(eps_var = 500, db = jazz, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "jazz['dbscan500by5JazzEvents'] = pd.DataFrame(dbscanJazzLabels)\n",
    "\n",
    "jazz['dbscan500by5JazzEvents'].hist()\n",
    "\n",
    "jazz.plot.scatter(y='BNGnorthing', x='BNGeasting', c='dbscan500by5JazzEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the different labels inside the db\n",
    "jazz.dbscan500by5JazzEvents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible colors\n",
    "colors = [\n",
    "    'red',\n",
    "    'blue',\n",
    "    'gray',\n",
    "    'darkred',\n",
    "    'lightred',\n",
    "    'orange',\n",
    "    'beige',\n",
    "    'green',\n",
    "    'darkgreen',\n",
    "    'lightgreen',\n",
    "    'darkblue',\n",
    "    'lightblue',\n",
    "    'purple',\n",
    "    'darkpurple',\n",
    "    'pink',\n",
    "    'cadetblue',\n",
    "    'lightgray',\n",
    "    'black']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new jazz list\n",
    "#trying out a map of this clustering\n",
    "#create a map with our data in center\n",
    "latList = jazz['lat'].tolist()\n",
    "lngList = jazz['lng'].tolist()\n",
    "clusterLabelList = jazz['dbscan500by5JazzEvents'].tolist()\n",
    "medLat = jazz['lat'].median()\n",
    "medLng = jazz['lng'].median()\n",
    "\n",
    "this_map = folium.Map([medLat, medLng], zoom_start=12, tiles=\"Cartodb Positron\", control_scale=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for lat, lng, label in zip(latList, lngList, clusterLabelList):\n",
    "    if label == -1:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='gray', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 0:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='blue', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 1:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='lightred', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 2:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='yellow', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 3:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='lightgreen', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 4:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='orange', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 5:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='purple', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 6:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='pink', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 7:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='lightblue', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 8:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='black', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 9:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='darkred', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 10:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='beige', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 11:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='cadetblue', fill_color='orange', fill_opacity=0.7))\n",
    "    elif label == 12:\n",
    "        this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='darkgreen', fill_color='orange', fill_opacity=0.7))\n",
    "    \n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
