{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some stuff\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#need to translate from wgs to bng to do spatial clustering\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly info\n",
    "plotly.tools.set_credentials_file(username='aclong', api_key='A9dlryDYONXram1rzbki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies number of rows to show\n",
    "pd.set_option('display.max_rows', 300) \n",
    "\n",
    "# specifies default number format to 4 decimal places\n",
    "pd.options.display.float_format = '{:40,.4f}'.format \n",
    "\n",
    "# specifies that graphs should use ggplot styling\n",
    "plt.style.use('ggplot') \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .env variable\n",
    "# base_dir = 'D:\\Documentos\\GitHub\\CityBlender'\n",
    "# dotenv_file = os.path.join(base_dir, '.env')\n",
    "\n",
    "base_dir = 'C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Analysis Test/'\n",
    "dotenv_file = os.path.join(base_dir, '.env')\n",
    "\n",
    "\n",
    "if os.path.isfile(dotenv_file):\n",
    "    load_dotenv(dotenv_file, verbose=True)\n",
    "    \n",
    "db_uri = os.getenv('DB_URI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new MongoDB Client\n",
    "db_client = MongoClient(str(db_uri))\n",
    "\n",
    "# If it's ok it should return a 1.0\n",
    "db_client.london.command(\"serverStatus\")['ok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a database to connect to (.london)\n",
    "db_london = db_client.london\n",
    "\n",
    "# choose a collection\n",
    "db_london_events = db_london['events']\n",
    "db_london_artist = db_london['artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup all the documents in a collection\n",
    "db_london_events.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.DataFrame(list(db_london_events.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For instance in the first row there are 3 events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put this in the date fomrat\n",
    "events['date'] = [(datetime.strptime(events['date'][x], '%Y-%m-%d')) for x in range(len(events['date']))]\n",
    "\n",
    "# Convert the dates into day name\n",
    "events['date_name'] = [(events['date'][x].strftime(\"%A\")) for x in range(len(events['date']))]\n",
    "\n",
    "# Lat & Long\n",
    "events['lat'] = [(events['location'][x]['lat']) for x in range(len(events['location']))]\n",
    "events['lng'] = [(events['location'][x]['lng']) for x in range(len(events['location']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from mpl_toolkits.basemap import Basemap   \n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, MultiPolygon\n",
    "from shapely.prepared import prep\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import Normalize\n",
    "from descartes import PolygonPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB SCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy import cluster\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(events['lng'], events['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = events[events['lat']<52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(subset['lng'], subset['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset[subset['lat']>51.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(subset['lng'], subset['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCANING_DB(eps_var = 600 , min_sample_var = 5, db = subset, lat_var = 'lat', lng_var = 'lng'):\n",
    "    dbscan = DBSCAN(eps=eps_var, min_samples = min_sample_var)\n",
    "#     print(dbscan) \n",
    "    arrey_coords = db[[lat_var, lng_var]].values\n",
    "    #print(arrey_coords)\n",
    "    #try clustering out on the whole dataset\n",
    "    dbscan_result = dbscan.fit(arrey_coords)\n",
    "    dbscan_result_lbls = dbscan_result.labels_\n",
    "    return(dbscan_result_lbls)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to BNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to translate from wgs to bng to do spatial clustering\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do clustering locations need to be in BNG so that distances are in metres\n",
    "#Define projections using EPSG codes\n",
    "wgs84=pyproj.Proj(\"+init=EPSG:4326\") # LatLon with WGS84 datum used by songkick\n",
    "osgb36=pyproj.Proj(\"+init=EPSG:27700\") # UK Ordnance Survey, 1936 datum, for locations in eastings/northings/metres\n",
    "\n",
    "#create a new pd without NaNs\n",
    "londonEventsdfNoNan = subset[subset['lat'].notnull()]\n",
    "\n",
    "#make new columns for the new latlng\n",
    "londonEventsdfNoNan['BNGnorthing'] = \"\"\n",
    "londonEventsdfNoNan['BNGeasting'] = \"\"\n",
    "\n",
    "#reset the index - londonEventsdfNoNan now main dataframe\n",
    "londonEventsdfNoNan = londonEventsdfNoNan.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run through the dataset and transform those coordinates\n",
    "origLat = []\n",
    "origLng = []\n",
    "\n",
    "for i in range(0,len(londonEventsdfNoNan)):\n",
    "    # print(i)\n",
    "    try:\n",
    "        origLat.append(londonEventsdfNoNan['lat'][i])\n",
    "        origLng.append(londonEventsdfNoNan['lng'][i])\n",
    "        \n",
    "    except:\n",
    "        origLat.append(np.nan)\n",
    "        origLng.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,lon = pyproj.transform(wgs84,osgb36,origLng,origLat)\n",
    "    \n",
    "londonEventsdfNoNan['BNGeasting'] = lat\n",
    "londonEventsdfNoNan['BNGnorthing'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now convert from object to numeric\n",
    "londonEventsdfNoNan['BNGnorthing'] = pd.to_numeric(londonEventsdfNoNan['BNGnorthing'])\n",
    "londonEventsdfNoNan['BNGeasting'] = pd.to_numeric(londonEventsdfNoNan['BNGeasting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "londonEventsdfNoNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['lng'], londonEventsdfNoNan['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['BNGeasting'], londonEventsdfNoNan['BNGnorthing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['lat'], londonEventsdfNoNan['BNGnorthing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(londonEventsdfNoNan['lng'], londonEventsdfNoNan['BNGeasting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = SCANING_DB(eps_var = 750, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', db = londonEventsdfNoNan)\n",
    "londonEventsdfNoNan['cluster'] = fitted\n",
    "print(len(londonEventsdfNoNan['cluster'].unique()))\n",
    "print(londonEventsdfNoNan.groupby('cluster').count()['_id'].sort_values(ascending = False))\n",
    "londonEventsdfNoNan['cluster'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to subset the genre depending on which dataset\n",
    "def subset_by_genre(db, lib = 'spotify', words = 'reggae'):\n",
    "    return db[db[lib].astype(str).str.contains(words, case=False)]\n",
    "\n",
    "#create a genre compiling function\n",
    "def genre_df_compiler(genreName, db = londonEventsdfNoNan):\n",
    "    firstEventsdf = subset_by_genre(db, lib='spotify',words = genreName)\n",
    "    secondEventsdf = subset_by_genre(db, lib='lastfm',words = genreName)\n",
    "    allEventsdf = \"all\"+genreName+\"Events\" \n",
    "    allEventsdf = pd.concat([firstEventsdf, secondEventsdf])\n",
    "    allEventsdf = allEventsdf.drop_duplicates(subset='_id', keep='last')\n",
    "    return(allEventsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_df_genre(db, epsMin = 1, epsMax = 2000, epsStep = 10, labelColName = \"ClusterNosjazz\", silColName = 'silhouScorejazz', lat_var = 'BNGnorthing', lng_var = 'BNGeasting'):\n",
    "    clusterNos = []\n",
    "    silhouScore = []\n",
    "    epsValues = list(range(epsMin, epsMax, epsStep))\n",
    "    epsDF = pd.DataFrame(epsValues)\n",
    "    for i in epsValues:\n",
    "        fitted = SCANING_DB(eps_var = i, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', db = db)\n",
    "        db['cluster'] = fitted\n",
    "        array_coords = db[[lat_var, lng_var]].values\n",
    "        silHouMet = metrics.silhouette_score(array_coords, fitted)\n",
    "        silhouScore.append(silHouMet)\n",
    "        clusterNos.append(len(db['cluster'].unique()))\n",
    "    epsDF[labelColName] = pd.DataFrame(clusterNos)\n",
    "    epsDF[silColName] = pd.DataFrame(silhouScore)\n",
    "    return epsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_silhouette_score(db = folk, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', labelColName = 'folk500by5Labels'):\n",
    "#     array_coords = db[[lat_var, lng_var]].values\n",
    "#     labelsList = db[labelColName].tolist()\n",
    "#     silHouMet = metrics.silhouette_score(array_coords, labelsList)\n",
    "#     return(silHouMet)\n",
    "# silHouMet = get_silhouette_score(db = jazz, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', labelColName = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsDFevents = eps_df_genre(db = londonEventsdfNoNan, labelColName = \"ClusterNosevents\", silColName = 'silhouScoreevents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz =  genre_df_compiler('jazz', db = londonEventsdfNoNan)\n",
    "jazz.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFjazz = eps_df_genre(db = jazz, labelColName = \"ClusterNosjazz\", silColName = 'silhouScorejazz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punk =  genre_df_compiler('punk', db = londonEventsdfNoNan)\n",
    "punk.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFpunk = eps_df_genre(db = punk, labelColName = \"ClusterNospunk\", silColName = 'silhouScorepunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "techno =  genre_df_compiler('techno', db = londonEventsdfNoNan)\n",
    "techno.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFtechno = eps_df_genre(db = techno, labelColName = \"ClusterNostechno\", silColName = 'silhouScoretechno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folk =  genre_df_compiler('folk', db = londonEventsdfNoNan)\n",
    "folk.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFfolk = eps_df_genre(db = folk, labelColName = \"ClusterNosfolk\", silColName = 'silhouScorefolk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical =  genre_df_compiler('classical', db = londonEventsdfNoNan)\n",
    "classical.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFclassical = eps_df_genre(db = classical, labelColName = \"ClusterNosclassical\", silColName = 'silhouScoreclassical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house =  genre_df_compiler('house', db = londonEventsdfNoNan)\n",
    "house.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFhouse = eps_df_genre(db = house, labelColName = \"ClusterNoshouse\", silColName = 'silhouScorehouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reggae =  genre_df_compiler('reggae', db = londonEventsdfNoNan)\n",
    "reggae.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFreggae = eps_df_genre(db = reggae, labelColName = \"ClusterNosreggae\", silColName = 'silhouScorereggae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall = pd.concat([epsDFevents, epsDFjazz, epsDFfolk, epsDFhouse, epsDFclassical, epsDFreggae, epsDFpunk, epsDFtechno], axis=1, join_axes=[epsDFevents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall = epsDFall.loc[:,~epsDFall.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScoreevents'], \n",
    "                    name = 'All Events', \n",
    "                    line = dict(color = ('rgb(205, 12, 24)'), width = 4))\n",
    "trace1 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScorejazz'], \n",
    "                    name = 'Jazz Events', \n",
    "                    line = dict(color = ('rgb(22, 96, 167)'), width = 4))\n",
    "trace2 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScorefolk'], \n",
    "                    name = 'Folk Events', \n",
    "                    line = dict(color = ('rgb(100, 12, 24)'), width = 4))\n",
    "trace3 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScorehouse'], \n",
    "                    name = 'House Events', \n",
    "                    line = dict(color = ('rgb(150, 96, 167)'), width = 4))\n",
    "trace4 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScoreclassical'], \n",
    "                    name = 'Classical Events', \n",
    "                    line = dict(color = ('rgb(70, 96, 167)'), width = 4))\n",
    "trace5 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScorereggae'], \n",
    "                    name = 'Reggae Events', \n",
    "                    line = dict(color = ('rgb(175, 200, 167)'), width = 4))\n",
    "trace6 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScorepunk'], \n",
    "                    name = 'Punk Events', \n",
    "                    line = dict(color = ('rgb(255, 96, 167)'), width = 4))\n",
    "trace7 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['silhouScoretechno'], \n",
    "                    name = 'Techno Events', \n",
    "                    line = dict(color = ('rgb(70, 96, 100)'), width = 4))\n",
    "\n",
    "graphData = [\n",
    "             trace0, \n",
    "             trace1, \n",
    "             trace2, \n",
    "             trace3, \n",
    "             trace4,\n",
    "             trace5,\n",
    "             trace6,\n",
    "             trace7\n",
    "            ]\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Silhouette Scores No. Clusters at EPS values',\n",
    "              xaxis = dict(title = 'EPS Value'),\n",
    "              yaxis = dict(title = 'Silhouette Score'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=graphData, layout=layout)\n",
    "py.iplot(fig, filename='EPS-change-diff-genres-silhouette-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosevents'], \n",
    "                    name = 'All Events', \n",
    "                    line = dict(color = ('rgb(205, 12, 24)'), width = 4))\n",
    "trace1 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosjazz'], \n",
    "                    name = 'Jazz Events', \n",
    "                    line = dict(color = ('rgb(22, 96, 167)'), width = 4))\n",
    "trace2 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosfolk'], \n",
    "                    name = 'Folk Events', \n",
    "                    line = dict(color = ('rgb(100, 12, 24)'), width = 4))\n",
    "trace3 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNoshouse'], \n",
    "                    name = 'House Events', \n",
    "                    line = dict(color = ('rgb(150, 96, 167)'), width = 4))\n",
    "trace4 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosclassical'], \n",
    "                    name = 'Classical Events', \n",
    "                    line = dict(color = ('rgb(70, 96, 167)'), width = 4))\n",
    "trace5 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNosreggae'], \n",
    "                    name = 'Reggae Events', \n",
    "                    line = dict(color = ('rgb(175, 200, 167)'), width = 4))\n",
    "trace6 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNospunk'], \n",
    "                    name = 'Punk Events', \n",
    "                    line = dict(color = ('rgb(255, 96, 167)'), width = 4))\n",
    "trace7 = go.Scatter(x=epsDFall[0], \n",
    "                    y = epsDFall['ClusterNostechno'], \n",
    "                    name = 'Techno Events', \n",
    "                    line = dict(color = ('rgb(70, 96, 100)'), width = 4))\n",
    "\n",
    "\n",
    "graphData = [\n",
    "#              trace0, \n",
    "             trace1, \n",
    "             trace2, \n",
    "             trace3, \n",
    "             trace4,\n",
    "             trace5,\n",
    "             trace6,\n",
    "             trace7\n",
    "            ]\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title = 'No. Clusters at EPS values',\n",
    "              xaxis = dict(title = 'EPS Value'),\n",
    "              yaxis = dict(title = 'No. Clusters'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=graphData, layout=layout)\n",
    "py.iplot(fig, filename='EPS-change-diff-genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_labelcol(db = folk, eps_var = 500, min_sample_var = 5, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', colName = 'folk500by5Labels'):\n",
    "    dbscanLabels = SCANING_DB(eps_var = eps_var, min_sample_var = min_sample_var, db = db, lat_var = lat_var, lng_var = lng_var)\n",
    "    db[colName] = pd.DataFrame(dbscanLabels)\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette_score(db = folk, lat_var = 'BNGnorthing', lng_var = 'BNGeasting', labelColName = 'folk500by5Labels'):\n",
    "    array_coords = db[[lat_var, lng_var]].values\n",
    "    labelsList = db[labelColName].tolist()\n",
    "    silHouMet = metrics.silhouette_score(array_coords, labelsList)\n",
    "    return(silHouMet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folkSihouScore = get_silhouette_score()\n",
    "print(folkSihouScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folk = get_cluster_labelcol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get folium map of clusters\n",
    "#need to create the function to add labels of clusters to the dataframe\n",
    "#eps 500 minsamples 5\n",
    "# def SCANING_DB(eps_var = 0.1 , min_sample_var = 5, db = subset, lat_var = 'lat', lng_var = 'lng'):\n",
    "#     dbscan = DBSCAN(eps=eps_var, min_samples = min_sample_var)\n",
    "#     print(dbscan) \n",
    "#     arrey_coords = db[[lat_var, lng_var]].values\n",
    "    #print(arrey_coords)\n",
    "# try clustering out on the whole dataset\n",
    "#     dbscan_result = dbscan.fit(arrey_coords)\n",
    "#     dbscan_result_lbls = dbscan_result.labels_\n",
    "#     return(dbscan_result_lbls)\n",
    "\n",
    "dbscanJazzLabels = SCANING_DB(eps_var = 500, db = jazz, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "jazz['dbscan500by5JazzEvents'] = pd.DataFrame(dbscanJazzLabels)\n",
    "\n",
    "jazz['dbscan500by5JazzEvents'].hist()\n",
    "\n",
    "jazz.plot.scatter(y='BNGnorthing', x='BNGeasting', c='dbscan500by5JazzEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsDFevents.ClusterNosevents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the different labels inside the db\n",
    "jazz.dbscan500by5JazzEvents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanJazzLabels = SCANING_DB(eps_var = 500, db = jazz, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "jazz['dbscan500by5jazzEvents'] = pd.DataFrame(dbscanJazzLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanFolkLabels = SCANING_DB(eps_var = 500, db = folk, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "folk['dbscan500by5folkEvents'] = pd.DataFrame(dbscanFolkLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanHouseLabels = SCANING_DB(eps_var = 500, db = house, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "house['dbscan500by5houseEvents'] = pd.DataFrame(dbscanHouseLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanClassicalLabels = SCANING_DB(eps_var = 500, db = classical, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "classical['dbscan500by5classicalEvents'] = pd.DataFrame(dbscanClassicalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanReggaeLabels = SCANING_DB(eps_var = 500, db = reggae, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "reggae['dbscan500by5reggaeEvents'] = pd.DataFrame(dbscanReggaeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanPunkLabels = SCANING_DB(eps_var = 500, db = punk, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "punk['dbscan500by5punkEvents'] = pd.DataFrame(dbscanPunkLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanTechnoLabels = SCANING_DB(eps_var = 500, db = techno, lat_var = 'BNGnorthing', lng_var = 'BNGeasting')\n",
    "\n",
    "techno['dbscan500by5technoEvents'] = pd.DataFrame(dbscanTechnoLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#possible colors\n",
    "colors = [\n",
    "    'red',\n",
    "    'blue',\n",
    "    'gray',\n",
    "    'darkred',\n",
    "    'lightred',\n",
    "    'orange',\n",
    "    'beige',\n",
    "    'green',\n",
    "    'darkgreen',\n",
    "    'lightgreen',\n",
    "    'darkblue',\n",
    "    'lightblue',\n",
    "    'purple',\n",
    "    'darkpurple',\n",
    "    'pink',\n",
    "    'cadetblue',\n",
    "    'lightgray',\n",
    "    'black']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folium_map_genreclusters(db = jazz, clusterLabelColName = 'dbscan500by5JazzEvents'):\n",
    "    latList = db['lat'].tolist()\n",
    "    lngList = db['lng'].tolist()\n",
    "    clusterLabelList = db[clusterLabelColName].tolist()\n",
    "    medLat = db['lat'].median()\n",
    "    medLng = db['lng'].median()\n",
    "    \n",
    "    this_map = folium.Map([medLat, medLng], zoom_start=12, tiles=\"cartodbdark_matter\", control_scale=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for lat, lng, label in zip(latList, lngList, clusterLabelList):\n",
    "            if label == -1:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='gray', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 0:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='blue', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 1:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='lightred', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 2:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='yellow', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 3:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='lightgreen', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 4:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='orange', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 5:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='purple', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 6:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='pink', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 7:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='lightblue', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 8:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='black', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 9:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='darkred', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 10:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='beige', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 11:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='cadetblue', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 12:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='darkgreen', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 13:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='darkblue', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 14:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='green', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 15:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='red', fill_color='orange', fill_opacity=0.7))\n",
    "            elif label == 16:\n",
    "                this_map.add_child(folium.CircleMarker([lat, lng], \n",
    "#                                            popup=label, \n",
    "                                           radius = 5, color='darkpurple', fill_color='orange', fill_opacity=0.7))\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    return(this_map)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jazzClusterMap = folium_map_genreclusters(db = jazz, clusterLabelColName = 'dbscan500by5jazzEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folkClusterMap = folium_map_genreclusters(db = folk, clusterLabelColName = 'dbscan500by5folkEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseClusterMap = folium_map_genreclusters(db = house, clusterLabelColName = 'dbscan500by5houseEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classicalClusterMap = folium_map_genreclusters(db = classical, clusterLabelColName = 'dbscan500by5classicalEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reggaeClusterMap = folium_map_genreclusters(db = reggae, clusterLabelColName = 'dbscan500by5reggaeEvents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punkClusterMap = folium_map_genreclusters(db = punk, clusterLabelColName = 'dbscan500by5punkEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technoClusterMap = folium_map_genreclusters(db = techno, clusterLabelColName = 'dbscan500by5technoEvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazzClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/jazzClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazzClusterMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folkClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/folkClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folkClusterMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classicalClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/classicalClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classicalClusterMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punkClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/punkClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "punkClusterMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technoClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/technoClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technoClusterMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reggaeClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/reggaeClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reggaeClusterMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseClusterMap.save('C:/Users/Alfie/Documents/MSc Smart Cities/Term 2/Spatial Data Capture Storage and Analysis/Coursework/Maps/houseClusterMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseClusterMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
